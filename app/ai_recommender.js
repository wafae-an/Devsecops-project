#!/usr/bin/env node
/**
 * ============================================================================
 * AI Recommender - Security Vulnerability Analysis with LLaMA (from Prompts)
 * ============================================================================
 * Ce script lit les prompts g√©n√©r√©s par le parser dans :
 *   ./parsed-security-reports/prompts/
 * et g√©n√®re des rapports HTML √† partir des r√©ponses du mod√®le LLaMA.
 *
 * Pr√©requis :
 * - Ollama install√© localement (https://ollama.ai)
 * - Mod√®le LLaMA t√©l√©charg√© : ollama pull llama3.2
 * - Node.js >= 18
 */

const fs = require('fs');
const path = require('path');
const http = require('http');

// ============================================================================
// CONFIGURATION
// ============================================================================
const PROMPTS_DIR = process.argv[2] 
  ? path.join(process.argv[2], 'prompts')
  : (process.env.PROMPTS_DIR || './parsed-security-reports/prompts');

const OUTPUT_DIR = process.argv[3] 
  ? process.argv[3]
  : (process.env.OUTPUT_DIR || './ai-reports');

const OLLAMA_HOST = process.env.OLLAMA_HOST || 'localhost';
const OLLAMA_PORT = process.env.OLLAMA_PORT || '11434';
const LLM_MODEL = process.env.LLM_MODEL || 'llama3.2';

console.log('üìã Configuration:');
console.log(`   - Prompts directory: ${PROMPTS_DIR}`);
console.log(`   - Output directory: ${OUTPUT_DIR}`);
console.log(`   - Ollama: ${OLLAMA_HOST}:${OLLAMA_PORT}`);
console.log(`   - Model: ${LLM_MODEL}`);

// ============================================================================
// OUTILS
// ============================================================================
function ensureDirectoryExists(dir) {
  if (!fs.existsSync(dir)) {
    fs.mkdirSync(dir, { recursive: true });
    console.log(`üìÅ Dossier cr√©√© : ${dir}`);
  }
}

function readPrompt(filePath) {
  if (!fs.existsSync(filePath)) {
    console.warn(`‚ö†Ô∏è Fichier prompt introuvable : ${filePath}`);
    return null;
  }
  return fs.readFileSync(filePath, 'utf-8');
}

function writeHTMLReport(filePath, content) {
  const html = `
<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>${path.basename(filePath)}</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 40px; background: #fafafa; color: #333; }
    h1 { color: #0d47a1; border-bottom: 3px solid #0d47a1; padding-bottom: 5px; }
    h2 { color: #1976d2; margin-top: 30px; }
    h3 { color: #424242; }
    pre { background: #eee; padding: 10px; border-radius: 6px; overflow-x: auto; }
    code { background: #e3f2fd; padding: 2px 6px; border-radius: 3px; font-family: monospace; }
    .severity-critical { color: #d32f2f; font-weight: bold; }
    .severity-high { color: #f57c00; font-weight: bold; }
    .severity-medium { color: #fbc02d; font-weight: bold; }
    .severity-low { color: #388e3c; font-weight: bold; }
    footer { margin-top: 40px; font-size: 0.85em; color: #777; text-align: center; }
  </style>
</head>
<body>
  ${content}
  <footer>
    <hr>
    <p>Rapport g√©n√©r√© par <b>AI Recommender (LLaMA)</b> ‚Äî ${new Date().toLocaleString('fr-FR')}</p>
  </footer>
</body>
</html>`;
  fs.writeFileSync(filePath, html, 'utf-8');
  console.log(`‚úÖ Rapport g√©n√©r√© : ${filePath}`);
}

function writeJSONSummary(filePath, data) {
  fs.writeFileSync(filePath, JSON.stringify(data, null, 2), 'utf-8');
  console.log(`üìÑ R√©sum√© JSON cr√©√© : ${filePath}`);
}

// ============================================================================
// INTERACTION AVEC LLaMA (OLLAMA)
// ============================================================================
function queryLLM(prompt) {
  return new Promise((resolve, reject) => {
    const postData = JSON.stringify({
      model: LLM_MODEL,
      prompt: prompt,
      stream: false,
      options: { temperature: 0.7, top_p: 0.9, max_tokens: 4096 }
    });

    const options = {
      hostname: OLLAMA_HOST,
      port: OLLAMA_PORT,
      path: '/api/generate',
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Content-Length': Buffer.byteLength(postData)
      },
      timeout: 120000
    };

    const req = http.request(options, res => {
      let data = '';
      res.on('data', chunk => (data += chunk));
      res.on('end', () => {
        try {
          const response = JSON.parse(data);
          resolve(response.response || '');
        } catch (e) {
          reject(new Error('Erreur parsing r√©ponse LLM: ' + e.message));
        }
      });
    });

    req.on('error', err => reject(err));
    req.on('timeout', () => {
      req.destroy();
      reject(new Error('Timeout Ollama'));
    });

    req.write(postData);
    req.end();
  });
}

// ============================================================================
// V√âRIFICATION DISPONIBILIT√â OLLAMA
// ============================================================================
function checkOllamaAvailability() {
  return new Promise((resolve) => {
    const options = {
      hostname: OLLAMA_HOST,
      port: OLLAMA_PORT,
      path: '/api/tags',
      method: 'GET',
      timeout: 5000
    };

    const req = http.request(options, res => {
      let data = '';
      res.on('data', chunk => (data += chunk));
      res.on('end', () => {
        try {
          const response = JSON.parse(data);
          const hasModel = response.models?.some(m => m.name.includes(LLM_MODEL));
          resolve({ available: true, hasModel });
        } catch (e) {
          resolve({ available: true, hasModel: false });
        }
      });
    });

    req.on('error', () => resolve({ available: false, hasModel: false }));
    req.on('timeout', () => {
      req.destroy();
      resolve({ available: false, hasModel: false });
    });

    req.end();
  });
}

// ============================================================================
// MAIN
// ============================================================================
(async () => {
  console.log('\nüöÄ D√©marrage du AI Recommender (√† partir des prompts)...\n');
  
  // Cr√©er le dossier de sortie
  ensureDirectoryExists(OUTPUT_DIR);

  // V√©rifier que le dossier des prompts existe
  if (!fs.existsSync(PROMPTS_DIR)) {
    console.error(`‚ùå Erreur : Le dossier de prompts n'existe pas : ${PROMPTS_DIR}`);
    console.log('üìù Cr√©ation d\'un rapport d\'erreur...');
    
    const errorReport = {
      status: 'error',
      message: 'Prompts directory not found',
      expected_path: PROMPTS_DIR,
      timestamp: new Date().toISOString()
    };
    
    writeJSONSummary(path.join(OUTPUT_DIR, 'error.json'), errorReport);
    process.exit(1);
  }

  // V√©rifier la disponibilit√© d'Ollama
  console.log('üîç V√©rification de la disponibilit√© d\'Ollama...');
  const ollamaStatus = await checkOllamaAvailability();
  
  if (!ollamaStatus.available) {
    console.warn('‚ö†Ô∏è Ollama n\'est pas disponible. Les rapports seront g√©n√©r√©s sans analyse IA.');
    console.log('üí° Pour utiliser l\'IA, installez Ollama : https://ollama.ai\n');
  } else if (!ollamaStatus.hasModel) {
    console.warn(`‚ö†Ô∏è Le mod√®le ${LLM_MODEL} n'est pas install√©.`);
    console.log(`üí° Installez-le avec : ollama pull ${LLM_MODEL}\n`);
  } else {
    console.log('‚úÖ Ollama est disponible et le mod√®le est pr√™t !\n');
  }

  // Lire les fichiers de prompts
  const promptFiles = fs.readdirSync(PROMPTS_DIR).filter(f => 
    f.endsWith('.txt') || f.endsWith('.md')
  );
  
  if (promptFiles.length === 0) {
    console.log('‚ö†Ô∏è Aucun prompt trouv√© dans', PROMPTS_DIR);
    
    const emptyReport = {
      status: 'no_prompts',
      message: 'No prompt files found',
      searched_in: PROMPTS_DIR,
      timestamp: new Date().toISOString()
    };
    
    writeJSONSummary(path.join(OUTPUT_DIR, 'status.json'), emptyReport);
    process.exit(0);
  }

  console.log(`üìÇ ${promptFiles.length} prompt(s) trouv√©(s)\n`);

  const summary = {
    total_prompts: promptFiles.length,
    processed: 0,
    failed: 0,
    reports: [],
    ollama_available: ollamaStatus.available && ollamaStatus.hasModel,
    timestamp: new Date().toISOString()
  };

  // Traiter chaque prompt
  for (const file of promptFiles) {
    const type = path.basename(file, path.extname(file)).toLowerCase();
    console.log(`üß† Traitement du prompt : ${file}`);
    
    const promptPath = path.join(PROMPTS_DIR, file);
    const prompt = readPrompt(promptPath);
    
    if (!prompt) {
      summary.failed++;
      continue;
    }

    try {
      let htmlContent;
      
      if (ollamaStatus.available && ollamaStatus.hasModel) {
        // G√©n√©rer avec l'IA
        const llmResponse = await queryLLM(prompt);
        htmlContent = `
          <h1>üîí ${type.toUpperCase()} Security Report</h1>
          <div class="ai-analysis">
            ${llmResponse}
          </div>
        `;
      } else {
        // G√©n√©rer sans l'IA (afficher le prompt seulement)
        htmlContent = `
          <h1>üîí ${type.toUpperCase()} Security Report</h1>
          <div class="warning" style="background: #fff3cd; padding: 15px; border-left: 4px solid #ffc107; margin: 20px 0;">
            <strong>‚ö†Ô∏è Rapport g√©n√©r√© sans analyse IA</strong>
            <p>Ollama n'√©tait pas disponible lors de la g√©n√©ration de ce rapport.</p>
          </div>
          <h2>üìã Prompt d'analyse</h2>
          <pre>${prompt}</pre>
        `;
      }
      
      const htmlPath = path.join(OUTPUT_DIR, `${type}_report.html`);
      writeHTMLReport(htmlPath, htmlContent);
      
      summary.processed++;
      summary.reports.push({
        type,
        file,
        output: path.basename(htmlPath),
        ai_processed: ollamaStatus.available && ollamaStatus.hasModel
      });
      
    } catch (error) {
      console.error(`‚ùå Erreur sur ${file} :`, error.message);
      summary.failed++;
    }
  }

  // G√©n√©rer le r√©sum√© JSON
  writeJSONSummary(path.join(OUTPUT_DIR, 'summary.json'), summary);

  // Rapport final
  console.log('\n' + '='.repeat(60));
  console.log('‚ú® Traitement termin√© !');
  console.log(`   ‚úÖ Rapports g√©n√©r√©s : ${summary.processed}`);
  console.log(`   ‚ùå √âchecs : ${summary.failed}`);
  console.log(`   üìÅ Dossier de sortie : ${OUTPUT_DIR}`);
  console.log('='.repeat(60) + '\n');
})();
